<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ray's Thoughts and Writings</title><link href="http://www.raydevblog.us/" rel="alternate"></link><link href="http://www.raydevblog.us/feeds/data-science.atom.xml" rel="self"></link><id>http://www.raydevblog.us/</id><updated>2013-12-08T10:00:00-08:00</updated><entry><title>Making Recommendations Part I - Item-based Collaborative Filtering</title><link href="http://www.raydevblog.us/making-recommendations-part-i-item-based-collaborative-filtering.html" rel="alternate"></link><updated>2013-12-08T10:00:00-08:00</updated><author><name>Ray Chen</name></author><id>tag:www.raydevblog.us,2013-12-08:making-recommendations-part-i-item-based-collaborative-filtering.html</id><summary type="html">&lt;p&gt;Recommender systems are popular on e-commerce web sites, to make personalized
recommendations for products or services. Using the &lt;a href="http://www.grouplens.org/datasets/movielens"&gt;MovieLens 100k&lt;/a&gt; 
dataset, I plan to build a recommnender system, which makes automatic recommendations 
when a user inputs a list of movie ratings.&lt;/p&gt;
&lt;p&gt;The "MovieLens 100k" data set consists of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10K ratings (1-5) from &lt;em&gt;943&lt;/em&gt; users on &lt;em&gt;1682&lt;/em&gt; movies.&lt;/li&gt;
&lt;li&gt;Each user has rated at least 20 movies.&lt;/li&gt;
&lt;li&gt;Simple demographic info for the users (age, gender, occupation, zip)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;User-based or Item-based Collaborative Filtering&lt;/h1&gt;
&lt;p&gt;Collaborative Filtering (CF) is the most popular recommendation technique. CF works by
building a database of preferences for items by users, and generates recommendations or
makes predictions based on user-user similarity or item-item similarity. A user-based 
CF algorithm represents a user as a N-dimensinal vector of items, where N is the number 
of distinct items. The algorithm generates recommendations for a user based on a few other 
users who are most similar to him/her. Rather than matching user to user, item-based CF 
represents an item as a M-dimensinal vector of users, where M is the number of distinct users.
It matches an user's rated items to similar items, then combines those similar items into 
a recommendation list.&lt;/p&gt;
&lt;p&gt;After pass "MovieLens 100K" data set, we have a user-item matrix (943x1682). In the case of 
user-based CF the similarity is computed along the rows of the matrix, while in the case of 
item-based CF the similarity is computed along the column. In practice, user-based CF shows
weakness evaluating large, sparse datasets. Thus, I choose item-based CF to build my recommender. &lt;/p&gt;
&lt;h1&gt;Similarity Computation&lt;/h1&gt;
&lt;p&gt;The basic idea in similarity computation between two items i and j is to first isolate the users
who have rated both of these items and then to apply a similarity computation technique to determine
the similarity s. There are a number of different ways to compute the similarity between items, such
as Euclidean distance, Jaccord coefficient, cosine similarity, Pearson's correlation coefficient. 
Euclidean distance is often used for dense, continuous data. For sparse data, which often consists 
of asymmetric attributes, we typically employ Jaccord coefficient or cosine similarity that ignore 
0-0 matches. However, Jaccord coefficient or cosine similariy does not take the scale of data into 
account. Thus, I choose adjusted cosine similarity and Pearson's correlation for similarity compuation. 
After similarity compuation, we can build a item similarity dictionary.&lt;/p&gt;
&lt;h3&gt;Pearson's Correlation&lt;/h3&gt;
&lt;p&gt;The similarity between two item i and j is measured by Pearson's correlation.  Let the set of users 
who both rated i and j are denoted by U, then the correlation is given by &lt;/p&gt;
&lt;p&gt;\begin{equation}
sim(i, j) = \frac{\sum_{u \in U}(R_{u,i} - \overline{R_{i}})(R_{u,j} - \overline{R_{j}})}{\sqrt{\sum_{u \in U}(R_{u,i} - \overline{R_{i}})^2}\sqrt{\sum_{u \in U}(R_{u,j} - \overline{R_{j}})^2}}
\end{equation}&lt;/p&gt;
&lt;h3&gt;Adjusted Consine Similarity&lt;/h3&gt;
&lt;p&gt;The adjusted consine similarity substracts the corresponding user average from each co-rated pair.
The similarity between items i and j is given by&lt;/p&gt;
&lt;p&gt;\begin{equation}
sim(i, j) = \frac{\sum_{u \in U}(R_{u,i} - \overline{R_{u}})(R_{u,j} - \overline{R_{u}})}{\sqrt{\sum_{u \in U}(R_{u,i} - \overline{R_{u}})^2}\sqrt{\sum_{u \in U}(R_{u,j} - \overline{R_{u}})^2}}
\end{equation}&lt;/p&gt;
&lt;h1&gt;Recommendation Generation&lt;/h1&gt;
&lt;p&gt;On an item i for a user u, we computes the prediction by computing the sum of ratings given by the user on the items
similar to i. Each rating is weighted by the corresponding similarity $s_{i,j}$ between items i and j. We can denote
the similar item set of item i as N, and the prediction $P_{u,i}$ as&lt;/p&gt;
&lt;p&gt;\begin{equation}
P_{u,i} = \frac{\sum_{j \in N}(s_{i,j}*R_{u,j})} {\sum_{j \in N}(\mid s_{i,j} \mid)}
\end{equation}&lt;/p&gt;
&lt;p&gt;The recommendations will consist of a set of similar items with high prediction values.&lt;/p&gt;
&lt;h1&gt;Python Implementation&lt;/h1&gt;
&lt;p&gt;A Python module of my recommender system is availabe in my &lt;a href="https://github.com/garudareiga/PyDMML/blob/master/recommendation_movie_lens/Recommendation.py"&gt;github reposity&lt;/a&gt;. The method to build a recommender system and make predictions for a user is
shown as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Recommendation&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_user&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;943&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_item&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1682&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ml-100k/u.data&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;do_item_based_collaborative_filtering&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item_similarity_pearson&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;user_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_user&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;make_recommendations&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The item-based collaborative filtering takes about 35~40 minutes using Pearson's corelation to&lt;br /&gt;
compute item similarity. Although building the item similarity takes a long item, recommendations 
are almost instantaneous afterwards. Therefore, item-based CF is efficient for a large dataset,
with the additional overhead of maintining the item similarity dictionary.&lt;/p&gt;</summary><category term="data mining"></category><category term="machine learning"></category></entry></feed>